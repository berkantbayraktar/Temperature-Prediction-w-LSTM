{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CENG501 - Spring2021 - PA3 - Task - temperature prediction with LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berkantbayraktar/Temperature-Prediction-w-LSTM/blob/master/CENG501_Spring2021_PA3_Task_temperature_prediction_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC1WVk2aEykn"
      },
      "source": [
        "# A Sequence Modeling Pipeline with PyTorch for Weather Prediction\n",
        "# CENG501 - Spring 2021 - PA3\n",
        "\n",
        "In this task, you are expected to experience and demonstrate a pipeline for training a recurrent network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvBph3MjXWHh"
      },
      "source": [
        "## 1 Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qwlNQ2mXYoN"
      },
      "source": [
        "# Import your modules here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAft9BpAFIH4"
      },
      "source": [
        "## 2 Dataset\n",
        "\n",
        "We will use the hourly temperature data for Basel (why Basel? because it was freely available) from [meteoblue](https://www.meteoblue.com/en/weather/archive/export/basel_switzerland_2661604?daterange=2021-06-01%20-%202021-06-23&domain=NEMSAUTO&params%5B%5D=temp2m&min=2021-06-16&max=2021-06-23&utc_offset=2&timeResolution=hourly&temperatureunit=CELSIUS&velocityunit=KILOMETER_PER_HOUR&energyunit=watts&lengthunit=metric&degree_day_type=10%3B30&gddBase=10&gddLimit=30) between 1 June 2021 and 23 June 2021. Here is a description of how you should prepare your dataset from this raw file:\n",
        "\n",
        "* Raw data is available [here](http://kovan.ceng.metu.edu.tr/~sinan/DL/Basel_weather.xlsx) as an XLSX file which was downloaded from [meteoblue](https://www.meteoblue.com/en/weather/archive/export/basel_switzerland_2661604?daterange=2021-06-01%20-%202021-06-23&domain=NEMSAUTO&params%5B%5D=temp2m&min=2021-06-16&max=2021-06-23&utc_offset=2&timeResolution=hourly&temperatureunit=CELSIUS&velocityunit=KILOMETER_PER_HOUR&energyunit=watts&lengthunit=metric&degree_day_type=10%3B30&gddBase=10&gddLimit=30).\n",
        "\n",
        "* Load the file into Python as a NumPy array using [Pandas](https://pp4e-book.github.io/chapters/ch10_scientific_libraries.html#data-handling-analysis-with-pandas). Filter out unnecessary information at the top and convert the first column to an hour index, starting at 0 and finishing at 551.\n",
        "\n",
        "* Split the data into two: A training set from the values between 1 June 2021 and 16 June 2021 (inclusive). A test set from the remaining values.\n",
        "\n",
        "* For each set, slide a time window of six hours and with a stride of 1, and for each position of the window, create a training input-output pair as follows:\n",
        "\n",
        "  $(\\mathbf{x}_i = <T_i, T_{i+1}, T_{i+2}, T_{i+3}, T_{i+4}>, y_i = T_{i+5}),$\n",
        " \n",
        "  where $T_i$ is the temperature at hour index $i$. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Loar-pkwQf1M"
      },
      "source": [
        "# Write your code here\n",
        "# If you like, you can create subsections here and split your code into \n",
        "# meaningfully separate parts, e.g. \"Loading the dataset\", \"Cleaning the dataset\",\n",
        "# \"Splitting the dataset\".."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9eN7WAcFKYC"
      },
      "source": [
        "## 3 Your LSTM Definition\n",
        "\n",
        "Implement your own LSTM \"cell\" using PyTorch without using PyTorch's LSTM implementation. However, you can use the backpropagation mechanism of PyTorch and therefore, you just need to worry about the feedforward processing.\n",
        "\n",
        "Your implementation should not be limited to the weather prediction problem and be general. For the sake of simplicity, you can just implement a single-layer LSTM cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYYD_dO3RI6U"
      },
      "source": [
        "# Your LSTM Definition \n",
        "import torch\n",
        "class MyLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        \"\"\"\n",
        "          input_size: the size of the input at a time step.\n",
        "          hidden_size: the number of neurons in the hidden state.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        ## @TODO: Create parameters in LSTM and initialize them\n",
        "        pass \n",
        "    \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "          X: A batch of sequences where each sequence has L time steps and for each time step, \n",
        "          it has input_size many elements. Has shape (B, L, input_size) with B being \n",
        "          the batch size.\n",
        "\n",
        "          Output: Tuple (h, c) where h is the tensor holding the hidden state for L\n",
        "          time steps, and c is the tensor holding the memory state for L time steps. \n",
        "          Both have shape (B, L, hidden_size).\n",
        "        \"\"\"\n",
        "        ## @TODO: Process X over L timesteps and return the output\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej7EMhi_FOZS"
      },
      "source": [
        "## 4 Your Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZjnU5VTUZxG"
      },
      "source": [
        "class MyWeatherPredictor(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        random.seed(501)\n",
        "        np.random.seed(501)\n",
        "        torch.manual_seed(501)\n",
        "\n",
        "        # @TODO: Create an instance of your LSTM model and a FC layer\n",
        "        # that maps the last hidden state to the output that you wish to \n",
        "        # estimate\n",
        "        pass\n",
        "\n",
        "    def forward(self, X):\n",
        "        # @TODO: Forward pass through LSTM and FC layer to estimate\n",
        "        # the target\n",
        "        pass\n",
        "\n",
        "        return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aSiszOcFRpz"
      },
      "source": [
        "## 5 Your Trainer\n",
        "\n",
        "Implement your training function here. You can use functions we have defined in the previous assignments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSbe6G6yVhjh"
      },
      "source": [
        "# Your implementation comes here\n",
        "\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfS43qOMFUSL"
      },
      "source": [
        "## 6 Train Your Model\n",
        "\n",
        "Create an instance of your model, a suitable loss function, a suitable optimizer and call the training function with suitable hyperparameters (learning rate, batch size, hidden size etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxGwItkQV1hT"
      },
      "source": [
        "# Your implementation comes here\n",
        "\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f1DoS6hFXBi"
      },
      "source": [
        "## 7 Analyze the Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgL-j3vNFZQF"
      },
      "source": [
        "### 7.1 Visualize the Loss Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qTDQ4zyV3Fd"
      },
      "source": [
        "# Your implementation comes here\n",
        "\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FhKN8bWFfDC"
      },
      "source": [
        "### 7.2 Quantitative Analysis\n",
        "\n",
        "Provide a quantitative analysis of your model on the test set using root mean squared error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHt0PJbdV5CW"
      },
      "source": [
        "# Your implementation comes here\n",
        "\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FvUOfTiFh4x"
      },
      "source": [
        "### 7.3 Qualitative Analysis\n",
        "\n",
        "Plot test data and your predictions over a sliding window. Plot two versions of your predictions: (i) Window sliding on the test data and you plot the predictions only. (ii) After obtaining the first prediction on the test data, window sliding over the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuzwFvd7V5rU"
      },
      "source": [
        "# Your implementation comes here\n",
        "\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sga8XVbNHUf"
      },
      "source": [
        "## 8 Tune Your Model\n",
        "\n",
        "Tune the following aspects for your model and provide a figure or a table in each case:\n",
        "\n",
        "- Number of hidden neurons.\n",
        "- Learning rate.\n",
        "- Batch size.\n",
        "\n",
        "Report the performance of the best model after tuning."
      ]
    }
  ]
}